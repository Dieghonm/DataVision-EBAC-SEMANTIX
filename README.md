# ğŸš€ ML Pipeline Orchestrator

Uma aplicaÃ§Ã£o web interativa para configurar, executar e avaliar pipelines de Machine Learning com interface Streamlit.

## âœ¨ CaracterÃ­sticas Principais

### ğŸ†• Novas Funcionalidades
- **ğŸ’¾ Salvamento de Modelos**: Salve modelos treinados com todas as informaÃ§Ãµes (scaler, feature selector, mÃ©tricas)
- **ğŸ”„ ReutilizaÃ§Ã£o de Modelos**: Carregue modelos salvos e use para novas prediÃ§Ãµes
- **ğŸ”® Sistema de PrediÃ§Ãµes**: Interface para prediÃ§Ãµes individuais ou em lote
- **ğŸ“Š MÃ©tricas em Destaque**: VisualizaÃ§Ã£o clara da performance dos modelos
- **ğŸ—‚ï¸ Gerenciamento de Modelos**: Liste, compare e gerencie todos os modelos salvos

### ğŸ”§ Funcionalidades Principais
- **ğŸ”§ ConfiguraÃ§Ã£o Visual**: Interface intuitiva para configurar todos os aspectos do pipeline
- **ğŸ“Š MÃºltiplos Algoritmos**: Random Forest, Logistic Regression, SVM
- **ğŸ“ˆ VisualizaÃ§Ãµes Interativas**: GrÃ¡ficos de avaliaÃ§Ã£o com Plotly
- **âš™ï¸ ConfiguraÃ§Ã£o YAML**: Pipelines reproduzÃ­veis via arquivos de configuraÃ§Ã£o
- **ğŸ“ Logging Detalhado**: Rastreamento completo de todas as etapas
- **ğŸ¯ MÃ©tricas Abrangentes**: Accuracy, Precision, Recall, F1, ROC-AUC
- **ğŸ“‚ Upload de Dados**: Suporte a datasets personalizados
- **ğŸ”„ Cross-Validation**: ValidaÃ§Ã£o cruzada integrada

## ğŸ—ï¸ Estrutura do Projeto

```
ml_pipeline_project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py                    # Interface Streamlit principal
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ orchestrator.py       # Orquestrador do pipeline
â”‚   â”‚   â”œâ”€â”€ data_processor.py     # Processamento de dados
â”‚   â”‚   â”œâ”€â”€ model_trainer.py      # Treinamento de modelos
â”‚   â”‚   â””â”€â”€ evaluator.py         # AvaliaÃ§Ã£o de modelos
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.py            # Sistema de logging
â”‚       â”œâ”€â”€ config_loader.py     # Carregamento de configuraÃ§Ãµes
â”‚       â””â”€â”€ model_manager.py     # Gerenciamento de modelos
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ default_config.yaml      # ConfiguraÃ§Ã£o padrÃ£o
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Dados brutos
â”‚   â”œâ”€â”€ processed/               # Dados processados
â”‚   â”œâ”€â”€ results/                 # Resultados e relatÃ³rios
â”‚   â””â”€â”€ models/                  # Modelos salvos
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ example_usage.py         # Exemplos de uso
â”œâ”€â”€ logs/                        # Arquivos de log
â””â”€â”€ requirements.txt
```

## ğŸš€ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### 1. Clone e Setup

```bash
# Clonar repositÃ³rio (ou criar diretÃ³rio)
mkdir ml_pipeline_project
cd ml_pipeline_project

# Executar setup
python setup.py
```

### 2. Instalar DependÃªncias

```bash
# Criar ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 3. Executar AplicaÃ§Ã£o

```bash
# Navegar para src
cd src

# Executar Streamlit
streamlit run app.py
```

**Acesse**: http://localhost:8501

## ğŸ¯ Como Usar

### ğŸ†• Modos de OperaÃ§Ã£o

A aplicaÃ§Ã£o agora possui 3 modos principais:

#### 1. **ğŸ“ Treinar Novo Modelo**
- Escolha dataset (Iris, Wine, Breast Cancer ou upload personalizado)
- Configure algoritmo e parÃ¢metros
- Define mÃ©tricas de avaliaÃ§Ã£o e cross-validation
- **Novo**: OpÃ§Ã£o de salvar o modelo automaticamente
- Visualize resultados e mÃ©tricas em destaque

#### 2. **ğŸ“ Usar Modelo Salvo**  
- Liste todos os modelos salvos com suas informaÃ§Ãµes
- Carregue modelo especÃ­fico com um clique
- Veja detalhes: algoritmo, acurÃ¡cia, features, data de criaÃ§Ã£o
- Modelo fica pronto para fazer prediÃ§Ãµes

#### 3. **ğŸ”® Fazer PrediÃ§Ãµes**
- **Entrada Manual**: Insira valores das features individualmente
- **Upload CSV**: FaÃ§a prediÃ§Ãµes em lote com arquivo CSV
- Visualize probabilidades por classe
- Download dos resultados em CSV
- GrÃ¡ficos de distribuiÃ§Ã£o das prediÃ§Ãµes

### ğŸ“Š VisualizaÃ§Ã£o de Resultados

#### MÃ©tricas em Destaque
- **Performance Cards**: Accuracy, F1, Precision, Recall com cores indicativas
- **Gauge ROC-AUC**: Medidor visual da Ã¡rea sob a curva ROC
- **RecomendaÃ§Ãµes AutomÃ¡ticas**: SugestÃµes baseadas na performance

#### VisualizaÃ§Ãµes Interativas
- Matriz de confusÃ£o com valores e percentuais
- Curvas ROC multiclasse
- ImportÃ¢ncia das features
- Curvas Precision-Recall
- DistribuiÃ§Ã£o de probabilidades

### ğŸ’¾ Gerenciamento de Modelos

#### Salvamento Inteligente
- Modelo principal (.pkl)
- Scaler de preprocessamento
- Feature selector
- InformaÃ§Ãµes completas (JSON)
- MÃ©tricas de performance
- ConfiguraÃ§Ã£o utilizada

#### Carregamento e ReutilizaÃ§Ã£o
- Lista modelos com preview das informaÃ§Ãµes
- Carregamento automÃ¡tico de preprocessadores
- ValidaÃ§Ã£o de features necessÃ¡rias
- AplicaÃ§Ã£o automÃ¡tica de transformaÃ§Ãµes

## ğŸ“Š Datasets IncluÃ­dos

### ClÃ¡ssicos (Sklearn)
- **Iris**: 150 amostras, 4 features, 3 classes - Perfeito para iniciantes
- **Wine**: 178 amostras, 13 features, 3 classes - ClassificaÃ§Ã£o quÃ­mica
- **Breast Cancer**: 569 amostras, 30 features, 2 classes - DiagnÃ³stico mÃ©dico

### Personalizados (Projetos Reais)
- **Credit Scoring**: AnÃ¡lise de risco de crÃ©dito
- **Hypertension**: PrediÃ§Ã£o de hipertensÃ£o arterial  
- **Phone Addiction**: DetecÃ§Ã£o de vÃ­cio em smartphones

### Upload Personalizado
- Suporte a qualquer CSV
- PrÃ©-processamento automÃ¡tico
- DetecÃ§Ã£o inteligente de target
- ConversÃ£o de tipos de dados

## âš™ï¸ ConfiguraÃ§Ã£o via YAML

### ConfiguraÃ§Ã£o Completa de Exemplo

```yaml
project:
  name: "Pipeline AvanÃ§ado"
  version: "2.0.0"

data:
  source: "wine"
  test_size: 0.3
  random_state: 42

preprocessing:
  scaling:
    method: "standard"  # standard, minmax, robust
  feature_selection:
    enabled: true
    method: "selectkbest"  # selectkbest, rfe
    k: 8
  handle_missing:
    strategy: "mean"  # mean, median, drop

model:
  algorithm: "random_forest"
  random_forest:
    n_estimators: 200
    max_depth: 15
    min_samples_split: 5
    random_state: 42

training:
  cross_validation:
    enabled: true
    cv_folds: 10
  hyperparameter_tuning:
    enabled: true
    method: "grid_search"  # grid_search, random_search

evaluation:
  metrics:
    - "accuracy"
    - "precision"
    - "recall" 
    - "f1"
    - "roc_auc"
  plots:
    - "confusion_matrix"
    - "roc_curve"
    - "feature_importance"
    - "precision_recall_curve"

pipeline_steps:
  - "load_data"
  - "preprocess_data"
  - "train_model" 
  - "evaluate_model"
  - "save_results"

output:
  save_model: true
  results_dir: "data/models"
```

## ğŸ¤– Algoritmos Suportados

### **Random Forest**
```yaml
random_forest:
  n_estimators: 100     # NÃºmero de Ã¡rvores
  max_depth: 10         # Profundidade mÃ¡xima
  min_samples_split: 2  # Amostras mÃ­n. para split
  min_samples_leaf: 1   # Amostras mÃ­n. por folha
  random_state: 42
```

### **Logistic Regression**
```yaml
logistic_regression:
  C: 1.0               # RegularizaÃ§Ã£o
  solver: "lbfgs"      # Algoritmo de otimizaÃ§Ã£o
  max_iter: 1000       # IteraÃ§Ãµes mÃ¡ximas
  random_state: 42
```

### **Support Vector Machine**
```yaml
svm:
  C: 1.0               # ParÃ¢metro de regularizaÃ§Ã£o
  kernel: "rbf"        # rbf, linear, poly
  gamma: "scale"       # Coeficiente do kernel
  probability: true    # Para prediÃ§Ãµes probabilÃ­sticas
  random_state: 42
```

## ğŸ”® Sistema de PrediÃ§Ãµes

### PrediÃ§Ã£o Individual
```python
# Via interface web:
# 1. Selecione "Fazer PrediÃ§Ãµes"
# 2. Escolha "Entrada Manual"
# 3. Insira valores das features
# 4. Clique "Fazer PrediÃ§Ã£o"

# Resultado:
# - Classe predita
# - Probabilidades por classe
# - GrÃ¡fico de barras das probabilidades
```

### PrediÃ§Ãµes em Lote
```python
# Via interface web:
# 1. Prepare CSV com as mesmas features do modelo
# 2. Selecione "Upload CSV"
# 3. FaÃ§a upload do arquivo
# 4. Clique "Fazer PrediÃ§Ãµes"

# Resultado:
# - Tabela com todas as prediÃ§Ãµes
# - Probabilidades por classe
# - GrÃ¡fico de distribuiÃ§Ã£o
# - Download dos resultados
```

### Via CÃ³digo Python
```python
from src.utils.model_manager import ModelManager
import pandas as pd

# Inicializar gerenciador
manager = ModelManager()

# Carregar dados
data = pd.read_csv("novos_dados.csv")

# Fazer prediÃ§Ãµes
results = manager.predict("meu_modelo", data)

print(f"PrediÃ§Ãµes: {results['predictions']}")
print(f"Probabilidades: {results['probabilities']}")
```

## ğŸ’¡ Exemplos PrÃ¡ticos

### Executar Exemplos Completos
```bash
python examples/example_usage.py
```

Este script demonstra:
1. âœ… Treinamento e salvamento de modelos
2. âœ… Carregamento e prediÃ§Ãµes
3. âœ… ComparaÃ§Ã£o de algoritmos
4. âœ… PrediÃ§Ãµes em lote
5. âœ… Gerenciamento de modelos

### Workflow TÃ­pico

#### 1. ExploraÃ§Ã£o de Dados
```python
# Carregue dataset na interface
# Visualize estatÃ­sticas e grÃ¡ficos
# Analise qualidade dos dados
# Identifique padrÃµes e correlaÃ§Ãµes
```

#### 2. ExperimentaÃ§Ã£o de Modelos
```python
# Teste diferentes algoritmos
# Compare performance
# Ajuste hiperparÃ¢metros
# Use cross-validation
```

#### 3. Modelo Final
```python
# Selecione melhor algoritmo
# Salve modelo com nome descritivo
# Exporte configuraÃ§Ã£o
# Documente resultados
```

#### 4. ProduÃ§Ã£o
```python
# Carregue modelo salvo
# FaÃ§a prediÃ§Ãµes em novos dados
# Monitore performance
# Atualize quando necessÃ¡rio
```

## ğŸ¨ Interface Web - Guia Visual

### Sidebar - Modos de OperaÃ§Ã£o
```
âš™ï¸ ConfiguraÃ§Ãµes do Pipeline
â”œâ”€â”€ ğŸ¯ Modo: [Treinar|Carregar|Predizer]
â”œâ”€â”€ ğŸ“‚ Dados
â”‚   â”œâ”€â”€ Fonte: [iris|wine|upload...]
â”‚   â””â”€â”€ ğŸ“¤ Upload CSV
â”œâ”€â”€ ğŸ¤– Modelo  
â”‚   â”œâ”€â”€ Algoritmo: [RF|LogReg|SVM]
â”‚   â””â”€â”€ ParÃ¢metros especÃ­ficos
â”œâ”€â”€ ğŸ“Š AvaliaÃ§Ã£o
â”‚   â”œâ”€â”€ Test Size: [0.1 - 0.5]
â”‚   â”œâ”€â”€ CV Folds: [3 - 10] 
â”‚   â””â”€â”€ MÃ©tricas: [â˜‘ï¸ accuracy â˜‘ï¸ f1...]
â””â”€â”€ ğŸš€ Executar Pipeline
```

### Main Area - Resultados
```
ğŸ“Š Resultados do Pipeline
â”œâ”€â”€ ğŸ“ˆ Cards de MÃ©tricas
â”‚   â”œâ”€â”€ âœ… Accuracy: 0.9567 (Excelente)
â”‚   â”œâ”€â”€ ğŸ“Š F1-Score: 0.9234 (Bom)  
â”‚   â”œâ”€â”€ ğŸ¯ Precision: 0.9445
â”‚   â””â”€â”€ ğŸ“ˆ Recall: 0.9123
â”œâ”€â”€ ğŸŒŸ ROC-AUC Gauge: 0.94
â”œâ”€â”€ ğŸ’¡ RecomendaÃ§Ãµes
â””â”€â”€ ğŸ“‘ Tabs: [MÃ©tricas|VisualizaÃ§Ãµes|Config|Logs]
```

## ğŸ“Š MÃ©tricas e InterpretaÃ§Ã£o

### Performance Cards
- **ğŸŸ¢ Excelente**: â‰¥ 0.90 (Verde)
- **ğŸŸ¡ Bom**: 0.80-0.89 (Amarelo)  
- **ğŸŸ  Regular**: 0.70-0.79 (Laranja)
- **ğŸ”´ Precisa Melhorar**: < 0.70 (Vermelho)

### ROC-AUC Gauge
- **0.9-1.0**: Excelente discriminaÃ§Ã£o
- **0.8-0.9**: Boa discriminaÃ§Ã£o
- **0.7-0.8**: DiscriminaÃ§Ã£o razoÃ¡vel
- **0.6-0.7**: DiscriminaÃ§Ã£o pobre
- **â‰¤0.5**: Sem discriminaÃ§Ã£o

### RecomendaÃ§Ãµes AutomÃ¡ticas
```
âœ… Excelente acurÃ¡cia! Modelo performando muito bem.
âš ï¸ Recall baixo. Considere balanceamento de classes.
ğŸ“Š Modelo conservador - boa precisÃ£o, recall menor.
âš ï¸ Alta variabilidade no CV. PossÃ­vel overfitting.
```

## ğŸ”§ ExtensÃµes e PersonalizaÃ§Ã£o

### Adicionando Novos Algoritmos
```python
# src/pipeline/model_trainer.py
def _initialize_model(self, algorithm):
    # ... algoritmos existentes ...
    elif algorithm == 'xgboost':
        import xgboost as xgb
        model = xgb.XGBClassifier(**model_params)
    # ...
```

### Novas MÃ©tricas
```python
# src/pipeline/evaluator.py
def calculate_metrics(self, y_true, y_pred, y_pred_proba=None):
    # ... mÃ©tricas existentes ...
    if 'balanced_accuracy' in self.config['evaluation']['metrics']:
        from sklearn.metrics import balanced_accuracy_score
        metrics['balanced_accuracy'] = balanced_accuracy_score(y_true, y_pred)
    # ...
```

### Preprocessadores Customizados
```python
# src/pipeline/data_processor.py
def _apply_custom_preprocessing(self, X_train, X_test):
    # Implementar transformaÃ§Ãµes especÃ­ficas
    # NormalizaÃ§Ã£o especÃ­fica do domÃ­nio
    # Feature engineering automÃ¡tico
    return X_train_processed, X_test_processed
```

## ğŸš€ Casos de Uso AvanÃ§ados

### 1. AnÃ¡lise Comparativa de Algoritmos
```python
# Compare mÃºltiplos algoritmos automaticamente
algorithms = ['random_forest', 'logistic_regression', 'svm']
results = compare_algorithms(algorithms, dataset='wine')
best_model = select_best_model(results, metric='f1_score')
```

### 2. Pipeline Automatizado de ProduÃ§Ã£o
```python
# Deploy automatizado
def production_pipeline():
    model = load_best_model()
    new_data = fetch_production_data()
    predictions = model.predict(new_data)
    save_predictions_to_db(predictions)
    monitor_model_drift(model, new_data)
```

### 3. A/B Testing de Modelos  
```python
# Teste diferentes versÃµes
model_a = load_model("model_v1")
model_b = load_model("model_v2")

results_a = evaluate_on_test_set(model_a, test_data)
results_b = evaluate_on_test_set(model_b, test_data)

winner = statistical_test(results_a, results_b)
```

## ğŸ” Troubleshooting

### Problemas Comuns

#### "Modelo nÃ£o encontrado"
```bash
# Verifique se o arquivo existe
ls data/models/
# Execute exemplo de treinamento
python examples/example_usage.py
```

#### "Features faltantes"
```python
# As features do CSV devem coincidir com o modelo
# Verifique nomes das colunas
model_features = manager.get_model_summary("modelo")['features']['names']
print("Features necessÃ¡rias:", model_features)
```

#### "Erro de memÃ³ria"
```yaml
# Reduza o dataset ou use algoritmos mais leves
data:
  test_size: 0.1  # Usar menos dados para teste

model:
  algorithm: "logistic_regression"  # Mais leve que RF
```

### Logs Detalhados
```bash
# Verificar logs para debugging
tail -f logs/ml_pipeline_*.log

# Ou via interface web na aba "Logs"
```

## ğŸ“ˆ Roadmap e Melhorias Futuras

### ğŸ”œ PrÃ³ximas VersÃµes
- [ ] **AutoML**: SeleÃ§Ã£o automÃ¡tica de algoritmos e hiperparÃ¢metros
- [ ] **Ensemble Methods**: CombinaÃ§Ã£o automÃ¡tica de modelos
- [ ] **Deep Learning**: IntegraÃ§Ã£o com redes neurais (TensorFlow/PyTorch)
- [ ] **Time Series**: Suporte a dados temporais
- [ ] **RegressÃ£o**: Pipelines para problemas de regressÃ£o
- [ ] **Interpretabilidade**: SHAP values e LIME
- [ ] **Deployment**: Export para produÃ§Ã£o (Docker, FastAPI)
- [ ] **Monitoring**: Drift detection e alertas

### ğŸŒŸ Melhorias Planejadas
- [ ] **Interface**: Temas dark/light, mais customizaÃ§Ã£o
- [ ] **Performance**: Processamento paralelo, cache de modelos
- [ ] **Dados**: Suporte a mais formatos (Parquet, JSON, SQL)
- [ ] **ColaboraÃ§Ã£o**: Multi-usuÃ¡rio, controle de versÃ£o de modelos
- [ ] **IntegraÃ§Ã£o**: MLflow, Weights & Biases, cloud providers

## ğŸ¤ Contribuindo

### Como Contribuir
1. ğŸ´ Fork o projeto
2. ğŸŒ¿ Crie branch: `git checkout -b feature/nova-funcionalidade`
3. ğŸ’» Implemente suas mudanÃ§as
4. âœ… Teste: `python -m pytest tests/`
5. ğŸ“ Commit: `git commit -m 'Adiciona nova funcionalidade'`
6. ğŸš€ Push: `git push origin feature/nova-funcionalidade`
7. ğŸ”„ Pull Request

### Diretrizes
- **CÃ³digo**: Siga PEP 8, adicione docstrings
- **Testes**: Cubra novas funcionalidades com testes
- **DocumentaÃ§Ã£o**: Atualize README e exemplos
- **Commit**: Mensagens claras e descritivas

## ğŸ“ LicenÃ§a

DistribuÃ­do sob a licenÃ§a MIT. Veja `LICENSE` para mais informaÃ§Ãµes.

## ğŸ“ Suporte e Contato

- ğŸ“§ **Email**: seu-email@exemplo.com
- ğŸ› **Issues**: [GitHub Issues](https://github.com/seu-usuario/ml-pipeline-orchestrator/issues)
- ğŸ“– **DocumentaÃ§Ã£o**: [Wiki do Projeto](https://github.com/seu-usuario/ml-pipeline-orchestrator/wiki)
- ğŸ’¬ **DiscussÃµes**: [GitHub Discussions](https://github.com/seu-usuario/ml-pipeline-orchestrator/discussions)

## ğŸ™ Agradecimentos

- **Streamlit**: Interface web fantÃ¡stica
- **Scikit-learn**: Base sÃ³lida para ML
- **Plotly**: VisualizaÃ§Ãµes interativas
- **Comunidade Python**: Ecossistema incrÃ­vel

---

**Desenvolvido com â¤ï¸ usando Streamlit, Scikit-learn e muito cafÃ© â˜•**

### ğŸŒŸ Se este projeto foi Ãºtil, considere dar uma estrela no GitHub!

```
â­ Star this repo | ğŸ´ Fork | ğŸ“¢ Share | ğŸ¤ Contribute
```